{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "766f9807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Donn√©es brutes lues avec succ√®s :\n",
      "  ID_Commande                 Texte_Brut (√Ä extraire par le LLM)\n",
      "0     ORD-A-1  La P-Alpha (48 kilos, 10 m¬≥) doit √™tre livr√©e....\n",
      "1     ORD-B-2  Note urgente : Le colis M-Beta fait environ 30...\n",
      "2     ORD-C-3  Pour le C-Gamma, il est √† 42 kg et 12 m¬≥. Sa v...\n",
      "3     ORD-D-4  Le plus important est le G-Delta, qui p√®se 36 ...\n",
      "4     ORD-E-5  N'oublie pas S-Epsilon (36 kg, 9 m¬≥). Valeur :...\n",
      "\n",
      "--- Informations sur le DataFrame ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 2 columns):\n",
      " #   Column                              Non-Null Count  Dtype \n",
      "---  ------                              --------------  ----- \n",
      " 0   ID_Commande                         10 non-null     object\n",
      " 1   Texte_Brut (√Ä extraire par le LLM)  10 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 292.0+ bytes\n",
      "‚ùå ERREUR : Le DataFrame ne contient pas la colonne 'Texte_Brut'. V√©rifiez l'orthographe de l'en-t√™te de colonne dans votre fichier Excel.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = r'C:\\Users\\HP\\Documents\\Projets\\Projet1\\data1.xlsx'\n",
    "\n",
    "try:\n",
    "    # Lire le fichier Excel dans un DataFrame Pandas\n",
    "    # Nous ajoutons l'encodage 'utf-8' au cas o√π il y aurait des caract√®res sp√©ciaux\n",
    "    df_brut = pd.read_excel(file_path)\n",
    "    \n",
    "    # Afficher les premi√®res lignes du DataFrame pour v√©rifier\n",
    "    print(\"‚úÖ Donn√©es brutes lues avec succ√®s :\")\n",
    "    print(df_brut.head())\n",
    "    \n",
    "    # Afficher le type de donn√©es et le nombre de lignes\n",
    "    print(\"\\n--- Informations sur le DataFrame ---\")\n",
    "    df_brut.info()\n",
    "    \n",
    "    # Stocker le texte brut pour l'√©tape suivante (Extraction LLM)\n",
    "    full_text_input = \"\\n\\n\".join(df_brut['Texte_Brut'].astype(str).tolist())\n",
    "    print(f\"\\nLe texte brut total √† analyser contient {len(full_text_input)} caract√®res.\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    # Cette erreur signifie que le fichier n'est pas trouv√© √† cet endroit pr√©cis\n",
    "    print(f\"‚ùå ERREUR : Le fichier n'a pas √©t√© trouv√© au chemin '{file_path}'.\")\n",
    "    print(\"V√©rifiez l'orthographe du chemin et le nom du fichier ('Projet 1 data RO.xlsx').\")\n",
    "except KeyError:\n",
    "    # Cette erreur signifie que les en-t√™tes de colonnes ne sont pas corrects\n",
    "    print(\"‚ùå ERREUR : Le DataFrame ne contient pas la colonne 'Texte_Brut'. V√©rifiez l'orthographe de l'en-t√™te de colonne dans votre fichier Excel.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Une erreur inattendue est survenue : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb7ce93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: pydantic in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.12.4)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-openai) (1.1.0)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.109.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-openai) (2.8.1)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic) (0.4.2)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-openai) (0.4.47)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-openai) (24.1)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-openai) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-openai) (9.1.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=1.109.1->langchain-openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.0->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-openai) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-openai) (0.25.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>4->openai<3.0.0,>=1.109.1->langchain-openai) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'DOSKEY' n'est pas reconnu en tant que commande interne\n",
      "ou externe, un programme exÔøΩcutable ou un fichier de commandes.\n",
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Installation des librairies\n",
    "!pip install pandas langchain-openai pydantic python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94fb3a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Sch√©ma Pydantic d√©fini.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "from langchain_openai import ChatOpenAI\n",
    "#from langchain.output_parsers import PydanticOutputParser\n",
    "#from langchain.prompts import PromptTemplate\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# --- 1. Charger la cl√© API ---\n",
    "# Assurez-vous d'avoir un fichier .env contenant : OPENAI_API_KEY=\"votre_cle\"\n",
    "load_dotenv() \n",
    "\n",
    "# ----------------------------------------------------\n",
    "# A. D√âFINITION DU SCH√âMA (Pydantic)\n",
    "# ----------------------------------------------------\n",
    "class Item(BaseModel):\n",
    "    \"\"\"Repr√©sente un colis ou un article √† charger.\"\"\"\n",
    "    # Description pr√©cise pour aider le LLM √† extraire la bonne information\n",
    "    ID_Colis: str = Field(description=\"L'identifiant unique de l'article (ex: P-Alpha, M-Beta).\")\n",
    "    Poids_kg: int = Field(description=\"Le poids de l'article en kilogrammes. DOIT √äTRE UN NOMBRE ENTIER.\")\n",
    "    Volume_m3: int = Field(description=\"Le volume de l'article en m√®tres cubes. DOIT √äTRE UN NOMBRE ENTIER.\")\n",
    "    Priorite: int = Field(description=\"Niveau de priorit√© ou valeur √† maximiser. DOIT √äTRE UN NOMBRE ENTIER.\")\n",
    "\n",
    "class ExtractedData(BaseModel):\n",
    "    \"\"\"Conteneur pour la liste de tous les items extraits du texte.\"\"\"\n",
    "    items: List[Item] = Field(description=\"La liste compl√®te de tous les articles trouv√©s dans la commande brute.\")\n",
    "\n",
    "print(\"‚úÖ Sch√©ma Pydantic d√©fini.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12717513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fichier lu et 10 lignes de commandes concat√©n√©es en une seule entr√©e pour le LLM.\n",
      "\n",
      "--- D√©but de l'input LLM ---\n",
      "La P-Alpha (48 kilos, 10 m¬≥) doit √™tre livr√©e. Priorit√© (valeur) : 10.\n",
      "\n",
      "Note urgente : Le colis M-Beta fait environ 30kg et seulement 8 m√®tres cubes. Il a une forte valeur : 30.\n",
      "\n",
      "Pour le C-Gamma, il est √† 42 kg et 12 m¬≥. Sa valeur est de 25.\n",
      "\n",
      "Le plus important est le G-Delta, qui p√®se 36 kg et fait ...\n"
     ]
    }
   ],
   "source": [
    "# Le chemin d'acc√®s complet (absolu) de votre fichier\n",
    "file_path = r'C:\\Users\\HP\\Documents\\Projets\\Projet1\\data1.xlsx' \n",
    "COLUMN_NAME = 'Texte_Brut (√Ä extraire par le LLM)' # Nom exact de la colonne\n",
    "\n",
    "try:\n",
    "    df_brut = pd.read_excel(file_path)\n",
    "    \n",
    "    # Concat√©ner tout le texte brut en une seule grande cha√Æne.\n",
    "    # Chaque commande sera s√©par√©e par un double saut de ligne pour aider le LLM.\n",
    "    full_text_input = \"\\n\\n\".join(df_brut[COLUMN_NAME].astype(str).tolist())\n",
    "    \n",
    "    print(f\"‚úÖ Fichier lu et {len(df_brut)} lignes de commandes concat√©n√©es en une seule entr√©e pour le LLM.\")\n",
    "    # Affiche un aper√ßu pour confirmation\n",
    "    print(\"\\n--- D√©but de l'input LLM ---\")\n",
    "    print(full_text_input[:300] + \"...\") \n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ERREUR lors de la lecture ou de la pr√©paration de l'input : {e}\")\n",
    "    # Arr√™te l'ex√©cution si les donn√©es n'ont pas pu √™tre charg√©es\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d569cea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-1.1.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: openai in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.8.1)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (1.1.0)\n",
      "Collecting langgraph<1.1.0,>=1.0.2 (from langchain)\n",
      "  Downloading langgraph-1.0.4-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (2.12.4)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (0.4.47)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (24.1)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (9.1.2)\n",
      "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph<1.1.0,>=1.0.2->langchain)\n",
      "  Downloading langgraph_checkpoint-3.0.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting langgraph-prebuilt<1.1.0,>=1.0.2 (from langgraph<1.1.0,>=1.0.2->langchain)\n",
      "  Downloading langgraph_prebuilt-1.0.5-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph<1.1.0,>=1.0.2->langchain)\n",
      "  Downloading langgraph_sdk-0.2.10-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.5.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.32.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.0->langchain) (3.0.0)\n",
      "Collecting ormsgpack>=1.12.0 (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain)\n",
      "  Downloading ormsgpack-1.12.0-cp312-cp312-win_amd64.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (0.25.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.3.0)\n",
      "Downloading langchain-1.1.0-py3-none-any.whl (101 kB)\n",
      "Downloading langgraph-1.0.4-py3-none-any.whl (157 kB)\n",
      "Downloading langgraph_checkpoint-3.0.1-py3-none-any.whl (46 kB)\n",
      "Downloading langgraph_prebuilt-1.0.5-py3-none-any.whl (35 kB)\n",
      "Downloading langgraph_sdk-0.2.10-py3-none-any.whl (58 kB)\n",
      "Downloading ormsgpack-1.12.0-cp312-cp312-win_amd64.whl (112 kB)\n",
      "Installing collected packages: ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph, langchain\n",
      "Successfully installed langchain-1.1.0 langgraph-1.0.4 langgraph-checkpoint-3.0.1 langgraph-prebuilt-1.0.5 langgraph-sdk-0.2.10 ormsgpack-1.12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'DOSKEY' n'est pas reconnu en tant que commande interne\n",
      "ou externe, un programme exÔøΩcutable ou un fichier de commandes.\n",
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain-openai openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2396eed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Remplace \"chemin/vers/.env\" par le chemin r√©el\n",
    "load_dotenv(dotenv_path=r'C:\\Users\\HP\\Documents\\Projets\\Projet1')\n",
    "\n",
    "print(os.getenv(\"OPENAI_API_KEY\"))  # Devrait afficher ta cl√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27bb642a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cl√© API OK : sk-p‚Ä¶\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # charge le .env\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "assert api_key is not None, \"Cl√© API non trouv√©e ! V√©rifie ton .env\"\n",
    "print(\"Cl√© API OK :\", api_key[:4] + \"‚Ä¶\")  # affiche seulement les 4 premiers caract√®res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97beabd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ D√©marrage de l'extraction LLM... (cela peut prendre quelques secondes)\n",
      "\n",
      "‚ùå ERREUR lors de l'extraction. V√©rifiez votre cl√© API ou si le LLM a renvoy√© un format incorrect : Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------\n",
    "# B. PR√âPARATION DES OUTILS LANGCHAIN (suite)\n",
    "# ----------------------------------------------------\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# 1. Configuration du LLM (si non fait dans la Cellule 2)\n",
    "# Nous utilisons gpt-3.5-turbo qui est rapide et efficace pour cette t√¢che.\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0 ,openai_api_key=os.getenv(\"OPENAI_API_KEY\")) \n",
    "\n",
    "# 2. Le Parser Pydantic pour formater la sortie\n",
    "parser = PydanticOutputParser(pydantic_object=ExtractedData)\n",
    "\n",
    "# 3. Le Prompt Engineering (Instruction donn√©e au LLM)\n",
    "format_instructions = parser.get_format_instructions()\n",
    "prompt_template = \"\"\"\n",
    "Tu es un expert en traitement de commandes logistiques. Ta t√¢che est d'analyser le TEXTE DE COMMANDE BRUT ci-dessous \n",
    "et d'en extraire TOUTES les informations d'articles, en respectant rigoureusement le FORMAT JSON STICT. \n",
    "Pour chaque item trouv√©, extrait son ID, son poids en kg, son volume en m3, et sa priorit√© (valeur). \n",
    "Convertis TOUTES les valeurs num√©riques en nombres ENTIERS (int).\n",
    "\n",
    "TEXTE DE COMMANDE BRUT:\n",
    "---\n",
    "{commande_text}\n",
    "---\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"commande_text\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions}\n",
    ")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# C. EX√âCUTION\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# La cha√Æne de LangChain : Prompt -> LLM -> Parser\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "print(\"üöÄ D√©marrage de l'extraction LLM... (cela peut prendre quelques secondes)\")\n",
    "\n",
    "try:\n",
    "    # Ex√©cuter l'extraction sur l'ensemble du texte concat√©n√©\n",
    "    extracted_data_pydantic = chain.invoke({\"commande_text\": full_text_input})\n",
    "    \n",
    "    # Transformer le mod√®le Pydantic en DataFrame Pandas\n",
    "    extracted_items = [item.model_dump() for item in extracted_data_pydantic.items]\n",
    "    df_clean = pd.DataFrame(extracted_items)\n",
    "    \n",
    "    # Enregistrer les donn√©es propres\n",
    "    df_clean.to_csv('donnees_propres_RO.csv', index=False)\n",
    "    \n",
    "    print(\"\\n‚úÖ Extraction termin√©e avec succ√®s!\")\n",
    "    print(f\"Donn√©es structur√©es enregistr√©es dans 'donnees_propres_RO.csv'\")\n",
    "    print(\"\\n--- Aper√ßu des donn√©es extraites (Pr√™tes pour la RO) ---\")\n",
    "    print(df_clean)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå ERREUR lors de l'extraction. V√©rifiez votre cl√© API ou si le LLM a renvoy√© un format incorrect : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54c0498c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cl√© API : None\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # charge le .env\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(\"Cl√© API :\", api_key)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
